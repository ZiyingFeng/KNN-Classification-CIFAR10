{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for doing most of our calculations\n",
    "import matplotlib.pyplot as plt# for plotting\n",
    "from cs231n.data_utils import load_CIFAR10 # function to load the CIFAR-10 dataset.\n",
    "\n",
    "# Load matplotlib images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# These are important for reloading any code you write in external .py files.\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the CIFAR-10 data\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized KNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function compute_L2_distances_vectorized() in the KNN class.\n",
    "# In this function, you ought to achieve the same L2 distance but WITHOUT any for loops.\n",
    "# Note, this is SPECIFIC for the L2 norm.\n",
    "\n",
    "time_start =time.time()\n",
    "dists_L2_vectorized = knn.compute_L2_distances_vectorized(X=X_test)\n",
    "print('Time to run code: {}'.format(time.time()-time_start))\n",
    "print('Difference in L2 distances between your KNN implementations (should be 0): {}'.format(np.linalg.norm(dists_L2 - dists_L2_vectorized, 'fro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function predict_labels in the KNN class.\n",
    "# Calculate the training error (num_incorrect / total_samples) \n",
    "#   from running knn.predict_labels with k=1\n",
    "\n",
    "error = 1\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Calculate the error rate by calling predict_labels on the test \n",
    "#   data with k = 1.  Store the error rate in the variable error.\n",
    "# ================================================================ #\n",
    "error = 1.0*np.sum((knn.predict_labels(dists = dists_L2_vectorized) - y_test) != 0) / y_test.shape[0]\n",
    "y_pred = knn.predict_labels(dists = dists_L2_vectorized)\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented this correctly, the error should be: 0.726.\n",
    "\n",
    "This means that the k-nearest neighbors classifier is right 27.4% of the time, which is not great, considering that chance levels are 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the number of nearest neighbors hyperparameter.\n",
    "\n",
    "In this section, we select different numbers of nearest neighbors and assess which one has the lowest k-fold cross validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start =time.time()\n",
    "\n",
    "ks = [1, 2, 3, 5, 7, 10, 15, 20, 25, 30]\n",
    "\n",
    "# ================================================================ #\n",
    "# YOUR CODE HERE:\n",
    "#   Calculate the cross-validation error for each k in ks, testing\n",
    "#   the trained model on each of the 5 folds.  Average these errors\n",
    "#   together and make a plot of k vs. cross-validation error. Since \n",
    "#   we are assuming L2 distance here, please use the vectorized code!\n",
    "#   Otherwise, you might be waiting a long time.\n",
    "# ================================================================ #\n",
    "train_error, val_error = (np.zeros(len(ks)), np.zeros(len(ks)))\n",
    "k_idx = 0\n",
    "for k in ks:    \n",
    "    for i in np.arange(num_folds):\n",
    "        knn.train(X=X_train_folds[i], y=y_train_folds[i])\n",
    "        dists_L2_vectorized = knn.compute_L2_distances_vectorized(X = X_test_fold[i])\n",
    "        y_pred = knn.predict_labels(dists = dists_L2_vectorized, k = k)\n",
    "        val_error[k_idx] += np.sum((y_pred - y_test_fold[i]) != 0) / y_test_fold[i].shape[0]        \n",
    "    val_error[k_idx] = 1.0*val_error[k_idx]/num_folds\n",
    "    k_idx += 1\n",
    "        \n",
    "plt.plot(ks, val_error)\n",
    "plt.xlabel('ks')\n",
    "plt.ylabel('error')\n",
    "\n",
    "# ================================================================ #\n",
    "# END YOUR CODE HERE\n",
    "# ================================================================ #\n",
    "\n",
    "print('Computation time: %.2f'%(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value of  is best amongst the tested $k$'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
